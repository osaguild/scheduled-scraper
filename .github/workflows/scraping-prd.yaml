name: scraping prd
on:
  schedule:
    - cron: "0 0 * * *"
  workflow_dispatch:
jobs:
  scraping:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        node-version: [16.x]
    steps:
      - name: install chrome
        run: |
          sudo apt update
          wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
          sudo apt install ./google-chrome-stable_current_amd64.deb
      - name: set up node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v2
        with:
          node-version: ${{ matrix.node-version }}
      - name: check out
        uses: actions/checkout@v2
        with:
          ref: main
      - name: install package
        run: |
          sudo apt update
          npx npm-check-updates chromedriver -u
          yarn
      - name: run script
        run: yarn run-kaldi
      - name: run script
        run: yarn run-shamaison
      - name: create a pull request
        id: pr
        uses: peter-evans/create-pull-request@v3
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          commit-message: update scraping data
          signoff: false
          title: update scraping data
          delete-branch: true
          labels: auto_merge
          branch: "create-pull-request/scraping"
          branch-suffix: "short-commit-hash"
          draft: false
      - name: auto merge
        run: gh pr merge ${{ steps.pr.outputs.pull-request-url }} --merge
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
